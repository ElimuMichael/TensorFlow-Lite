{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.4"
    },
    "colab": {
      "name": "regression.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSuWDBraN4VX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "outputId": "1de497f3-a10d-49bc-bb2e-7e32a2d00c8d"
      },
      "source": [
        "!pip install -U \"tensorflow-gpu==2.0b1\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0b1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2b/53/e18c5e7a2263d3581a979645a185804782e59b8e13f42b9c3c3cfb5bb503/tensorflow_gpu-2.0.0b1-cp36-cp36m-manylinux1_x86_64.whl (348.9MB)\n",
            "\u001b[K     |████████████████████████████████| 348.9MB 67kB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0b1) (0.2.2)\n",
            "Requirement already satisfied, skipping upgrade: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0b1) (1.16.5)\n",
            "Requirement already satisfied, skipping upgrade: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0b1) (0.1.7)\n",
            "Requirement already satisfied, skipping upgrade: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0b1) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0b1) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0b1) (1.11.2)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019060502,>=1.14.0.dev2019060501 (from tensorflow-gpu==2.0b1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/dd/99c47dd007dcf10d63fd895611b063732646f23059c618a373e85019eb0e/tf_estimator_nightly-1.14.0.dev2019060501-py2.py3-none-any.whl (496kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 45.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0b1) (1.12.0)\n",
            "Requirement already satisfied, skipping upgrade: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0b1) (0.8.0)\n",
            "Requirement already satisfied, skipping upgrade: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0b1) (3.7.1)\n",
            "Requirement already satisfied, skipping upgrade: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0b1) (0.33.6)\n",
            "Requirement already satisfied, skipping upgrade: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0b1) (1.0.8)\n",
            "Requirement already satisfied, skipping upgrade: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0b1) (1.15.0)\n",
            "Collecting tb-nightly<1.14.0a20190604,>=1.14.0a20190603 (from tensorflow-gpu==2.0b1)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a4/96/571b875cd81dda9d5dfa1422a4f9d749e67c0a8d4f4f0b33a4e5f5f35e27/tb_nightly-1.14.0a20190603-py3-none-any.whl (3.1MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1MB 42.1MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0b1) (1.1.0)\n",
            "Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0b1) (41.2.0)\n",
            "Requirement already satisfied, skipping upgrade: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow-gpu==2.0b1) (2.8.0)\n",
            "Requirement already satisfied, skipping upgrade: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0b1) (0.16.0)\n",
            "Requirement already satisfied, skipping upgrade: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.14.0a20190604,>=1.14.0a20190603->tensorflow-gpu==2.0b1) (3.1.1)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.14.0a20190603 tensorflow-gpu-2.0.0b1 tf-estimator-nightly-1.14.0.dev2019060501\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eiY-Z0uWO5Ui",
        "colab_type": "text"
      },
      "source": [
        "Import the necessary paackages required for the project implementation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NdZEDg5XO0El",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense\n",
        "\n",
        "from google.colab import files\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQ99ng2GN4Ve",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Generate some sample dataset to train the regression model\n",
        "x = [-1, 0, 1, 2, 3, 4]\n",
        "y = [-3, -1, 1, 3, 5, 7]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpkXERiaPhGa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "7124e1ba-7d09-4161-e418-f4a9af8dc404"
      },
      "source": [
        "# Visualize the plot of the data\n",
        "plt.plot(x, y)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe039366128>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXYAAAD8CAYAAABjAo9vAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nil1EJMj8L+gyX0NSPiJEAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1u2PxHSPlaF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create a sequential model with one layer to perform the training\n",
        "model = models.Sequential([\n",
        "    Dense(units=1, input_shape = [1])\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rdxv_hJSBPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Compile the model using SGD optimizer and MSE loss function \n",
        "model.compile(optimizer=\"sgd\", loss=\"mse\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INB07ERzS12L",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "80f4a463-75da-40ae-cda4-387482d9c0fa"
      },
      "source": [
        "model.fit(x, y, epochs=300)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 6 samples\n",
            "Epoch 1/300\n",
            "6/6 [==============================] - 0s 674us/sample - loss: 0.0286\n",
            "Epoch 2/300\n",
            "6/6 [==============================] - 0s 479us/sample - loss: 0.0280\n",
            "Epoch 3/300\n",
            "6/6 [==============================] - 0s 720us/sample - loss: 0.0274\n",
            "Epoch 4/300\n",
            "6/6 [==============================] - 0s 352us/sample - loss: 0.0268\n",
            "Epoch 5/300\n",
            "6/6 [==============================] - 0s 267us/sample - loss: 0.0263\n",
            "Epoch 6/300\n",
            "6/6 [==============================] - 0s 757us/sample - loss: 0.0257\n",
            "Epoch 7/300\n",
            "6/6 [==============================] - 0s 369us/sample - loss: 0.0252\n",
            "Epoch 8/300\n",
            "6/6 [==============================] - 0s 375us/sample - loss: 0.0247\n",
            "Epoch 9/300\n",
            "6/6 [==============================] - 0s 460us/sample - loss: 0.0242\n",
            "Epoch 10/300\n",
            "6/6 [==============================] - 0s 371us/sample - loss: 0.0237\n",
            "Epoch 11/300\n",
            "6/6 [==============================] - 0s 309us/sample - loss: 0.0232\n",
            "Epoch 12/300\n",
            "6/6 [==============================] - 0s 665us/sample - loss: 0.0227\n",
            "Epoch 13/300\n",
            "6/6 [==============================] - 0s 340us/sample - loss: 0.0223\n",
            "Epoch 14/300\n",
            "6/6 [==============================] - 0s 333us/sample - loss: 0.0218\n",
            "Epoch 15/300\n",
            "6/6 [==============================] - 0s 318us/sample - loss: 0.0214\n",
            "Epoch 16/300\n",
            "6/6 [==============================] - 0s 344us/sample - loss: 0.0209\n",
            "Epoch 17/300\n",
            "6/6 [==============================] - 0s 323us/sample - loss: 0.0205\n",
            "Epoch 18/300\n",
            "6/6 [==============================] - 0s 471us/sample - loss: 0.0201\n",
            "Epoch 19/300\n",
            "6/6 [==============================] - 0s 477us/sample - loss: 0.0197\n",
            "Epoch 20/300\n",
            "6/6 [==============================] - 0s 216us/sample - loss: 0.0193\n",
            "Epoch 21/300\n",
            "6/6 [==============================] - 0s 308us/sample - loss: 0.0189\n",
            "Epoch 22/300\n",
            "6/6 [==============================] - 0s 317us/sample - loss: 0.0185\n",
            "Epoch 23/300\n",
            "6/6 [==============================] - 0s 258us/sample - loss: 0.0181\n",
            "Epoch 24/300\n",
            "6/6 [==============================] - 0s 438us/sample - loss: 0.0177\n",
            "Epoch 25/300\n",
            "6/6 [==============================] - 0s 305us/sample - loss: 0.0174\n",
            "Epoch 26/300\n",
            "6/6 [==============================] - 0s 224us/sample - loss: 0.0170\n",
            "Epoch 27/300\n",
            "6/6 [==============================] - 0s 535us/sample - loss: 0.0167\n",
            "Epoch 28/300\n",
            "6/6 [==============================] - 0s 219us/sample - loss: 0.0163\n",
            "Epoch 29/300\n",
            "6/6 [==============================] - 0s 224us/sample - loss: 0.0160\n",
            "Epoch 30/300\n",
            "6/6 [==============================] - 0s 571us/sample - loss: 0.0156\n",
            "Epoch 31/300\n",
            "6/6 [==============================] - 0s 467us/sample - loss: 0.0153\n",
            "Epoch 32/300\n",
            "6/6 [==============================] - 0s 373us/sample - loss: 0.0150\n",
            "Epoch 33/300\n",
            "6/6 [==============================] - 0s 465us/sample - loss: 0.0147\n",
            "Epoch 34/300\n",
            "6/6 [==============================] - 0s 231us/sample - loss: 0.0144\n",
            "Epoch 35/300\n",
            "6/6 [==============================] - 0s 261us/sample - loss: 0.0141\n",
            "Epoch 36/300\n",
            "6/6 [==============================] - 0s 251us/sample - loss: 0.0138\n",
            "Epoch 37/300\n",
            "6/6 [==============================] - 0s 298us/sample - loss: 0.0135\n",
            "Epoch 38/300\n",
            "6/6 [==============================] - 0s 211us/sample - loss: 0.0133\n",
            "Epoch 39/300\n",
            "6/6 [==============================] - 0s 292us/sample - loss: 0.0130\n",
            "Epoch 40/300\n",
            "6/6 [==============================] - 0s 364us/sample - loss: 0.0127\n",
            "Epoch 41/300\n",
            "6/6 [==============================] - 0s 273us/sample - loss: 0.0125\n",
            "Epoch 42/300\n",
            "6/6 [==============================] - 0s 267us/sample - loss: 0.0122\n",
            "Epoch 43/300\n",
            "6/6 [==============================] - 0s 252us/sample - loss: 0.0119\n",
            "Epoch 44/300\n",
            "6/6 [==============================] - 0s 278us/sample - loss: 0.0117\n",
            "Epoch 45/300\n",
            "6/6 [==============================] - 0s 255us/sample - loss: 0.0115\n",
            "Epoch 46/300\n",
            "6/6 [==============================] - 0s 259us/sample - loss: 0.0112\n",
            "Epoch 47/300\n",
            "6/6 [==============================] - 0s 248us/sample - loss: 0.0110\n",
            "Epoch 48/300\n",
            "6/6 [==============================] - 0s 242us/sample - loss: 0.0108\n",
            "Epoch 49/300\n",
            "6/6 [==============================] - 0s 254us/sample - loss: 0.0105\n",
            "Epoch 50/300\n",
            "6/6 [==============================] - 0s 254us/sample - loss: 0.0103\n",
            "Epoch 51/300\n",
            "6/6 [==============================] - 0s 246us/sample - loss: 0.0101\n",
            "Epoch 52/300\n",
            "6/6 [==============================] - 0s 274us/sample - loss: 0.0099\n",
            "Epoch 53/300\n",
            "6/6 [==============================] - 0s 317us/sample - loss: 0.0097\n",
            "Epoch 54/300\n",
            "6/6 [==============================] - 0s 248us/sample - loss: 0.0095\n",
            "Epoch 55/300\n",
            "6/6 [==============================] - 0s 265us/sample - loss: 0.0093\n",
            "Epoch 56/300\n",
            "6/6 [==============================] - 0s 254us/sample - loss: 0.0091\n",
            "Epoch 57/300\n",
            "6/6 [==============================] - 0s 315us/sample - loss: 0.0089\n",
            "Epoch 58/300\n",
            "6/6 [==============================] - 0s 297us/sample - loss: 0.0088\n",
            "Epoch 59/300\n",
            "6/6 [==============================] - 0s 378us/sample - loss: 0.0086\n",
            "Epoch 60/300\n",
            "6/6 [==============================] - 0s 255us/sample - loss: 0.0084\n",
            "Epoch 61/300\n",
            "6/6 [==============================] - 0s 251us/sample - loss: 0.0082\n",
            "Epoch 62/300\n",
            "6/6 [==============================] - 0s 253us/sample - loss: 0.0081\n",
            "Epoch 63/300\n",
            "6/6 [==============================] - 0s 238us/sample - loss: 0.0079\n",
            "Epoch 64/300\n",
            "6/6 [==============================] - 0s 371us/sample - loss: 0.0077\n",
            "Epoch 65/300\n",
            "6/6 [==============================] - 0s 318us/sample - loss: 0.0076\n",
            "Epoch 66/300\n",
            "6/6 [==============================] - 0s 247us/sample - loss: 0.0074\n",
            "Epoch 67/300\n",
            "6/6 [==============================] - 0s 257us/sample - loss: 0.0073\n",
            "Epoch 68/300\n",
            "6/6 [==============================] - 0s 232us/sample - loss: 0.0071\n",
            "Epoch 69/300\n",
            "6/6 [==============================] - 0s 254us/sample - loss: 0.0070\n",
            "Epoch 70/300\n",
            "6/6 [==============================] - 0s 285us/sample - loss: 0.0068\n",
            "Epoch 71/300\n",
            "6/6 [==============================] - 0s 248us/sample - loss: 0.0067\n",
            "Epoch 72/300\n",
            "6/6 [==============================] - 0s 337us/sample - loss: 0.0065\n",
            "Epoch 73/300\n",
            "6/6 [==============================] - 0s 264us/sample - loss: 0.0064\n",
            "Epoch 74/300\n",
            "6/6 [==============================] - 0s 248us/sample - loss: 0.0063\n",
            "Epoch 75/300\n",
            "6/6 [==============================] - 0s 264us/sample - loss: 0.0061\n",
            "Epoch 76/300\n",
            "6/6 [==============================] - 0s 265us/sample - loss: 0.0060\n",
            "Epoch 77/300\n",
            "6/6 [==============================] - 0s 266us/sample - loss: 0.0059\n",
            "Epoch 78/300\n",
            "6/6 [==============================] - 0s 269us/sample - loss: 0.0058\n",
            "Epoch 79/300\n",
            "6/6 [==============================] - 0s 367us/sample - loss: 0.0057\n",
            "Epoch 80/300\n",
            "6/6 [==============================] - 0s 248us/sample - loss: 0.0055\n",
            "Epoch 81/300\n",
            "6/6 [==============================] - 0s 350us/sample - loss: 0.0054\n",
            "Epoch 82/300\n",
            "6/6 [==============================] - 0s 256us/sample - loss: 0.0053\n",
            "Epoch 83/300\n",
            "6/6 [==============================] - 0s 276us/sample - loss: 0.0052\n",
            "Epoch 84/300\n",
            "6/6 [==============================] - 0s 312us/sample - loss: 0.0051\n",
            "Epoch 85/300\n",
            "6/6 [==============================] - 0s 321us/sample - loss: 0.0050\n",
            "Epoch 86/300\n",
            "6/6 [==============================] - 0s 310us/sample - loss: 0.0049\n",
            "Epoch 87/300\n",
            "6/6 [==============================] - 0s 253us/sample - loss: 0.0048\n",
            "Epoch 88/300\n",
            "6/6 [==============================] - 0s 294us/sample - loss: 0.0047\n",
            "Epoch 89/300\n",
            "6/6 [==============================] - 0s 269us/sample - loss: 0.0046\n",
            "Epoch 90/300\n",
            "6/6 [==============================] - 0s 289us/sample - loss: 0.0045\n",
            "Epoch 91/300\n",
            "6/6 [==============================] - 0s 261us/sample - loss: 0.0044\n",
            "Epoch 92/300\n",
            "6/6 [==============================] - 0s 267us/sample - loss: 0.0043\n",
            "Epoch 93/300\n",
            "6/6 [==============================] - 0s 326us/sample - loss: 0.0042\n",
            "Epoch 94/300\n",
            "6/6 [==============================] - 0s 267us/sample - loss: 0.0041\n",
            "Epoch 95/300\n",
            "6/6 [==============================] - 0s 259us/sample - loss: 0.0041\n",
            "Epoch 96/300\n",
            "6/6 [==============================] - 0s 352us/sample - loss: 0.0040\n",
            "Epoch 97/300\n",
            "6/6 [==============================] - 0s 272us/sample - loss: 0.0039\n",
            "Epoch 98/300\n",
            "6/6 [==============================] - 0s 332us/sample - loss: 0.0038\n",
            "Epoch 99/300\n",
            "6/6 [==============================] - 0s 266us/sample - loss: 0.0037\n",
            "Epoch 100/300\n",
            "6/6 [==============================] - 0s 254us/sample - loss: 0.0037\n",
            "Epoch 101/300\n",
            "6/6 [==============================] - 0s 355us/sample - loss: 0.0036\n",
            "Epoch 102/300\n",
            "6/6 [==============================] - 0s 321us/sample - loss: 0.0035\n",
            "Epoch 103/300\n",
            "6/6 [==============================] - 0s 280us/sample - loss: 0.0034\n",
            "Epoch 104/300\n",
            "6/6 [==============================] - 0s 269us/sample - loss: 0.0034\n",
            "Epoch 105/300\n",
            "6/6 [==============================] - 0s 390us/sample - loss: 0.0033\n",
            "Epoch 106/300\n",
            "6/6 [==============================] - 0s 339us/sample - loss: 0.0032\n",
            "Epoch 107/300\n",
            "6/6 [==============================] - 0s 277us/sample - loss: 0.0032\n",
            "Epoch 108/300\n",
            "6/6 [==============================] - 0s 295us/sample - loss: 0.0031\n",
            "Epoch 109/300\n",
            "6/6 [==============================] - 0s 271us/sample - loss: 0.0030\n",
            "Epoch 110/300\n",
            "6/6 [==============================] - 0s 256us/sample - loss: 0.0030\n",
            "Epoch 111/300\n",
            "6/6 [==============================] - 0s 304us/sample - loss: 0.0029\n",
            "Epoch 112/300\n",
            "6/6 [==============================] - 0s 319us/sample - loss: 0.0029\n",
            "Epoch 113/300\n",
            "6/6 [==============================] - 0s 328us/sample - loss: 0.0028\n",
            "Epoch 114/300\n",
            "6/6 [==============================] - 0s 343us/sample - loss: 0.0027\n",
            "Epoch 115/300\n",
            "6/6 [==============================] - 0s 529us/sample - loss: 0.0027\n",
            "Epoch 116/300\n",
            "6/6 [==============================] - 0s 401us/sample - loss: 0.0026\n",
            "Epoch 117/300\n",
            "6/6 [==============================] - 0s 426us/sample - loss: 0.0026\n",
            "Epoch 118/300\n",
            "6/6 [==============================] - 0s 387us/sample - loss: 0.0025\n",
            "Epoch 119/300\n",
            "6/6 [==============================] - 0s 293us/sample - loss: 0.0025\n",
            "Epoch 120/300\n",
            "6/6 [==============================] - 0s 424us/sample - loss: 0.0024\n",
            "Epoch 121/300\n",
            "6/6 [==============================] - 0s 347us/sample - loss: 0.0024\n",
            "Epoch 122/300\n",
            "6/6 [==============================] - 0s 348us/sample - loss: 0.0023\n",
            "Epoch 123/300\n",
            "6/6 [==============================] - 0s 320us/sample - loss: 0.0023\n",
            "Epoch 124/300\n",
            "6/6 [==============================] - 0s 283us/sample - loss: 0.0022\n",
            "Epoch 125/300\n",
            "6/6 [==============================] - 0s 362us/sample - loss: 0.0022\n",
            "Epoch 126/300\n",
            "6/6 [==============================] - 0s 331us/sample - loss: 0.0021\n",
            "Epoch 127/300\n",
            "6/6 [==============================] - 0s 344us/sample - loss: 0.0021\n",
            "Epoch 128/300\n",
            "6/6 [==============================] - 0s 356us/sample - loss: 0.0020\n",
            "Epoch 129/300\n",
            "6/6 [==============================] - 0s 292us/sample - loss: 0.0020\n",
            "Epoch 130/300\n",
            "6/6 [==============================] - 0s 393us/sample - loss: 0.0020\n",
            "Epoch 131/300\n",
            "6/6 [==============================] - 0s 346us/sample - loss: 0.0019\n",
            "Epoch 132/300\n",
            "6/6 [==============================] - 0s 375us/sample - loss: 0.0019\n",
            "Epoch 133/300\n",
            "6/6 [==============================] - 0s 440us/sample - loss: 0.0018\n",
            "Epoch 134/300\n",
            "6/6 [==============================] - 0s 276us/sample - loss: 0.0018\n",
            "Epoch 135/300\n",
            "6/6 [==============================] - 0s 256us/sample - loss: 0.0018\n",
            "Epoch 136/300\n",
            "6/6 [==============================] - 0s 282us/sample - loss: 0.0017\n",
            "Epoch 137/300\n",
            "6/6 [==============================] - 0s 273us/sample - loss: 0.0017\n",
            "Epoch 138/300\n",
            "6/6 [==============================] - 0s 370us/sample - loss: 0.0017\n",
            "Epoch 139/300\n",
            "6/6 [==============================] - 0s 353us/sample - loss: 0.0016\n",
            "Epoch 140/300\n",
            "6/6 [==============================] - 0s 360us/sample - loss: 0.0016\n",
            "Epoch 141/300\n",
            "6/6 [==============================] - 0s 457us/sample - loss: 0.0016\n",
            "Epoch 142/300\n",
            "6/6 [==============================] - 0s 342us/sample - loss: 0.0015\n",
            "Epoch 143/300\n",
            "6/6 [==============================] - 0s 272us/sample - loss: 0.0015\n",
            "Epoch 144/300\n",
            "6/6 [==============================] - 0s 273us/sample - loss: 0.0015\n",
            "Epoch 145/300\n",
            "6/6 [==============================] - 0s 265us/sample - loss: 0.0014\n",
            "Epoch 146/300\n",
            "6/6 [==============================] - 0s 290us/sample - loss: 0.0014\n",
            "Epoch 147/300\n",
            "6/6 [==============================] - 0s 276us/sample - loss: 0.0014\n",
            "Epoch 148/300\n",
            "6/6 [==============================] - 0s 270us/sample - loss: 0.0014\n",
            "Epoch 149/300\n",
            "6/6 [==============================] - 0s 277us/sample - loss: 0.0013\n",
            "Epoch 150/300\n",
            "6/6 [==============================] - 0s 280us/sample - loss: 0.0013\n",
            "Epoch 151/300\n",
            "6/6 [==============================] - 0s 246us/sample - loss: 0.0013\n",
            "Epoch 152/300\n",
            "6/6 [==============================] - 0s 290us/sample - loss: 0.0012\n",
            "Epoch 153/300\n",
            "6/6 [==============================] - 0s 268us/sample - loss: 0.0012\n",
            "Epoch 154/300\n",
            "6/6 [==============================] - 0s 269us/sample - loss: 0.0012\n",
            "Epoch 155/300\n",
            "6/6 [==============================] - 0s 269us/sample - loss: 0.0012\n",
            "Epoch 156/300\n",
            "6/6 [==============================] - 0s 310us/sample - loss: 0.0011\n",
            "Epoch 157/300\n",
            "6/6 [==============================] - 0s 263us/sample - loss: 0.0011\n",
            "Epoch 158/300\n",
            "6/6 [==============================] - 0s 283us/sample - loss: 0.0011\n",
            "Epoch 159/300\n",
            "6/6 [==============================] - 0s 262us/sample - loss: 0.0011\n",
            "Epoch 160/300\n",
            "6/6 [==============================] - 0s 260us/sample - loss: 0.0011\n",
            "Epoch 161/300\n",
            "6/6 [==============================] - 0s 316us/sample - loss: 0.0010\n",
            "Epoch 162/300\n",
            "6/6 [==============================] - 0s 281us/sample - loss: 0.0010\n",
            "Epoch 163/300\n",
            "6/6 [==============================] - 0s 356us/sample - loss: 9.8991e-04\n",
            "Epoch 164/300\n",
            "6/6 [==============================] - 0s 358us/sample - loss: 9.6958e-04\n",
            "Epoch 165/300\n",
            "6/6 [==============================] - 0s 2ms/sample - loss: 9.4966e-04\n",
            "Epoch 166/300\n",
            "6/6 [==============================] - 0s 522us/sample - loss: 9.3016e-04\n",
            "Epoch 167/300\n",
            "6/6 [==============================] - 0s 367us/sample - loss: 9.1105e-04\n",
            "Epoch 168/300\n",
            "6/6 [==============================] - 0s 316us/sample - loss: 8.9234e-04\n",
            "Epoch 169/300\n",
            "6/6 [==============================] - 0s 319us/sample - loss: 8.7401e-04\n",
            "Epoch 170/300\n",
            "6/6 [==============================] - 0s 263us/sample - loss: 8.5606e-04\n",
            "Epoch 171/300\n",
            "6/6 [==============================] - 0s 270us/sample - loss: 8.3847e-04\n",
            "Epoch 172/300\n",
            "6/6 [==============================] - 0s 300us/sample - loss: 8.2125e-04\n",
            "Epoch 173/300\n",
            "6/6 [==============================] - 0s 352us/sample - loss: 8.0438e-04\n",
            "Epoch 174/300\n",
            "6/6 [==============================] - 0s 346us/sample - loss: 7.8786e-04\n",
            "Epoch 175/300\n",
            "6/6 [==============================] - 0s 337us/sample - loss: 7.7167e-04\n",
            "Epoch 176/300\n",
            "6/6 [==============================] - 0s 346us/sample - loss: 7.5583e-04\n",
            "Epoch 177/300\n",
            "6/6 [==============================] - 0s 341us/sample - loss: 7.4030e-04\n",
            "Epoch 178/300\n",
            "6/6 [==============================] - 0s 484us/sample - loss: 7.2509e-04\n",
            "Epoch 179/300\n",
            "6/6 [==============================] - 0s 253us/sample - loss: 7.1020e-04\n",
            "Epoch 180/300\n",
            "6/6 [==============================] - 0s 273us/sample - loss: 6.9561e-04\n",
            "Epoch 181/300\n",
            "6/6 [==============================] - 0s 350us/sample - loss: 6.8133e-04\n",
            "Epoch 182/300\n",
            "6/6 [==============================] - 0s 346us/sample - loss: 6.6733e-04\n",
            "Epoch 183/300\n",
            "6/6 [==============================] - 0s 382us/sample - loss: 6.5363e-04\n",
            "Epoch 184/300\n",
            "6/6 [==============================] - 0s 284us/sample - loss: 6.4020e-04\n",
            "Epoch 185/300\n",
            "6/6 [==============================] - 0s 391us/sample - loss: 6.2705e-04\n",
            "Epoch 186/300\n",
            "6/6 [==============================] - 0s 345us/sample - loss: 6.1417e-04\n",
            "Epoch 187/300\n",
            "6/6 [==============================] - 0s 350us/sample - loss: 6.0155e-04\n",
            "Epoch 188/300\n",
            "6/6 [==============================] - 0s 342us/sample - loss: 5.8919e-04\n",
            "Epoch 189/300\n",
            "6/6 [==============================] - 0s 361us/sample - loss: 5.7709e-04\n",
            "Epoch 190/300\n",
            "6/6 [==============================] - 0s 361us/sample - loss: 5.6524e-04\n",
            "Epoch 191/300\n",
            "6/6 [==============================] - 0s 425us/sample - loss: 5.5363e-04\n",
            "Epoch 192/300\n",
            "6/6 [==============================] - 0s 390us/sample - loss: 5.4226e-04\n",
            "Epoch 193/300\n",
            "6/6 [==============================] - 0s 418us/sample - loss: 5.3112e-04\n",
            "Epoch 194/300\n",
            "6/6 [==============================] - 0s 321us/sample - loss: 5.2021e-04\n",
            "Epoch 195/300\n",
            "6/6 [==============================] - 0s 319us/sample - loss: 5.0952e-04\n",
            "Epoch 196/300\n",
            "6/6 [==============================] - 0s 301us/sample - loss: 4.9905e-04\n",
            "Epoch 197/300\n",
            "6/6 [==============================] - 0s 295us/sample - loss: 4.8881e-04\n",
            "Epoch 198/300\n",
            "6/6 [==============================] - 0s 365us/sample - loss: 4.7876e-04\n",
            "Epoch 199/300\n",
            "6/6 [==============================] - 0s 396us/sample - loss: 4.6893e-04\n",
            "Epoch 200/300\n",
            "6/6 [==============================] - 0s 378us/sample - loss: 4.5930e-04\n",
            "Epoch 201/300\n",
            "6/6 [==============================] - 0s 392us/sample - loss: 4.4986e-04\n",
            "Epoch 202/300\n",
            "6/6 [==============================] - 0s 383us/sample - loss: 4.4062e-04\n",
            "Epoch 203/300\n",
            "6/6 [==============================] - 0s 297us/sample - loss: 4.3157e-04\n",
            "Epoch 204/300\n",
            "6/6 [==============================] - 0s 300us/sample - loss: 4.2271e-04\n",
            "Epoch 205/300\n",
            "6/6 [==============================] - 0s 314us/sample - loss: 4.1403e-04\n",
            "Epoch 206/300\n",
            "6/6 [==============================] - 0s 290us/sample - loss: 4.0552e-04\n",
            "Epoch 207/300\n",
            "6/6 [==============================] - 0s 295us/sample - loss: 3.9719e-04\n",
            "Epoch 208/300\n",
            "6/6 [==============================] - 0s 366us/sample - loss: 3.8903e-04\n",
            "Epoch 209/300\n",
            "6/6 [==============================] - 0s 279us/sample - loss: 3.8104e-04\n",
            "Epoch 210/300\n",
            "6/6 [==============================] - 0s 377us/sample - loss: 3.7321e-04\n",
            "Epoch 211/300\n",
            "6/6 [==============================] - 0s 389us/sample - loss: 3.6555e-04\n",
            "Epoch 212/300\n",
            "6/6 [==============================] - 0s 329us/sample - loss: 3.5804e-04\n",
            "Epoch 213/300\n",
            "6/6 [==============================] - 0s 434us/sample - loss: 3.5069e-04\n",
            "Epoch 214/300\n",
            "6/6 [==============================] - 0s 329us/sample - loss: 3.4348e-04\n",
            "Epoch 215/300\n",
            "6/6 [==============================] - 0s 397us/sample - loss: 3.3643e-04\n",
            "Epoch 216/300\n",
            "6/6 [==============================] - 0s 448us/sample - loss: 3.2952e-04\n",
            "Epoch 217/300\n",
            "6/6 [==============================] - 0s 321us/sample - loss: 3.2275e-04\n",
            "Epoch 218/300\n",
            "6/6 [==============================] - 0s 588us/sample - loss: 3.1612e-04\n",
            "Epoch 219/300\n",
            "6/6 [==============================] - 0s 504us/sample - loss: 3.0963e-04\n",
            "Epoch 220/300\n",
            "6/6 [==============================] - 0s 372us/sample - loss: 3.0327e-04\n",
            "Epoch 221/300\n",
            "6/6 [==============================] - 0s 480us/sample - loss: 2.9703e-04\n",
            "Epoch 222/300\n",
            "6/6 [==============================] - 0s 485us/sample - loss: 2.9093e-04\n",
            "Epoch 223/300\n",
            "6/6 [==============================] - 0s 318us/sample - loss: 2.8496e-04\n",
            "Epoch 224/300\n",
            "6/6 [==============================] - 0s 606us/sample - loss: 2.7910e-04\n",
            "Epoch 225/300\n",
            "6/6 [==============================] - 0s 519us/sample - loss: 2.7337e-04\n",
            "Epoch 226/300\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 2.6776e-04\n",
            "Epoch 227/300\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 2.6226e-04\n",
            "Epoch 228/300\n",
            "6/6 [==============================] - 0s 1ms/sample - loss: 2.5687e-04\n",
            "Epoch 229/300\n",
            "6/6 [==============================] - 0s 380us/sample - loss: 2.5159e-04\n",
            "Epoch 230/300\n",
            "6/6 [==============================] - 0s 345us/sample - loss: 2.4643e-04\n",
            "Epoch 231/300\n",
            "6/6 [==============================] - 0s 313us/sample - loss: 2.4136e-04\n",
            "Epoch 232/300\n",
            "6/6 [==============================] - 0s 311us/sample - loss: 2.3640e-04\n",
            "Epoch 233/300\n",
            "6/6 [==============================] - 0s 283us/sample - loss: 2.3155e-04\n",
            "Epoch 234/300\n",
            "6/6 [==============================] - 0s 570us/sample - loss: 2.2679e-04\n",
            "Epoch 235/300\n",
            "6/6 [==============================] - 0s 397us/sample - loss: 2.2213e-04\n",
            "Epoch 236/300\n",
            "6/6 [==============================] - 0s 392us/sample - loss: 2.1757e-04\n",
            "Epoch 237/300\n",
            "6/6 [==============================] - 0s 426us/sample - loss: 2.1310e-04\n",
            "Epoch 238/300\n",
            "6/6 [==============================] - 0s 369us/sample - loss: 2.0873e-04\n",
            "Epoch 239/300\n",
            "6/6 [==============================] - 0s 394us/sample - loss: 2.0444e-04\n",
            "Epoch 240/300\n",
            "6/6 [==============================] - 0s 320us/sample - loss: 2.0024e-04\n",
            "Epoch 241/300\n",
            "6/6 [==============================] - 0s 322us/sample - loss: 1.9613e-04\n",
            "Epoch 242/300\n",
            "6/6 [==============================] - 0s 313us/sample - loss: 1.9210e-04\n",
            "Epoch 243/300\n",
            "6/6 [==============================] - 0s 299us/sample - loss: 1.8815e-04\n",
            "Epoch 244/300\n",
            "6/6 [==============================] - 0s 368us/sample - loss: 1.8429e-04\n",
            "Epoch 245/300\n",
            "6/6 [==============================] - 0s 373us/sample - loss: 1.8050e-04\n",
            "Epoch 246/300\n",
            "6/6 [==============================] - 0s 279us/sample - loss: 1.7679e-04\n",
            "Epoch 247/300\n",
            "6/6 [==============================] - 0s 278us/sample - loss: 1.7316e-04\n",
            "Epoch 248/300\n",
            "6/6 [==============================] - 0s 275us/sample - loss: 1.6960e-04\n",
            "Epoch 249/300\n",
            "6/6 [==============================] - 0s 304us/sample - loss: 1.6612e-04\n",
            "Epoch 250/300\n",
            "6/6 [==============================] - 0s 441us/sample - loss: 1.6271e-04\n",
            "Epoch 251/300\n",
            "6/6 [==============================] - 0s 310us/sample - loss: 1.5937e-04\n",
            "Epoch 252/300\n",
            "6/6 [==============================] - 0s 336us/sample - loss: 1.5609e-04\n",
            "Epoch 253/300\n",
            "6/6 [==============================] - 0s 391us/sample - loss: 1.5289e-04\n",
            "Epoch 254/300\n",
            "6/6 [==============================] - 0s 403us/sample - loss: 1.4975e-04\n",
            "Epoch 255/300\n",
            "6/6 [==============================] - 0s 272us/sample - loss: 1.4667e-04\n",
            "Epoch 256/300\n",
            "6/6 [==============================] - 0s 258us/sample - loss: 1.4366e-04\n",
            "Epoch 257/300\n",
            "6/6 [==============================] - 0s 294us/sample - loss: 1.4071e-04\n",
            "Epoch 258/300\n",
            "6/6 [==============================] - 0s 380us/sample - loss: 1.3782e-04\n",
            "Epoch 259/300\n",
            "6/6 [==============================] - 0s 291us/sample - loss: 1.3499e-04\n",
            "Epoch 260/300\n",
            "6/6 [==============================] - 0s 271us/sample - loss: 1.3221e-04\n",
            "Epoch 261/300\n",
            "6/6 [==============================] - 0s 347us/sample - loss: 1.2950e-04\n",
            "Epoch 262/300\n",
            "6/6 [==============================] - 0s 357us/sample - loss: 1.2684e-04\n",
            "Epoch 263/300\n",
            "6/6 [==============================] - 0s 270us/sample - loss: 1.2423e-04\n",
            "Epoch 264/300\n",
            "6/6 [==============================] - 0s 282us/sample - loss: 1.2168e-04\n",
            "Epoch 265/300\n",
            "6/6 [==============================] - 0s 295us/sample - loss: 1.1918e-04\n",
            "Epoch 266/300\n",
            "6/6 [==============================] - 0s 259us/sample - loss: 1.1673e-04\n",
            "Epoch 267/300\n",
            "6/6 [==============================] - 0s 298us/sample - loss: 1.1433e-04\n",
            "Epoch 268/300\n",
            "6/6 [==============================] - 0s 269us/sample - loss: 1.1199e-04\n",
            "Epoch 269/300\n",
            "6/6 [==============================] - 0s 337us/sample - loss: 1.0969e-04\n",
            "Epoch 270/300\n",
            "6/6 [==============================] - 0s 316us/sample - loss: 1.0743e-04\n",
            "Epoch 271/300\n",
            "6/6 [==============================] - 0s 243us/sample - loss: 1.0523e-04\n",
            "Epoch 272/300\n",
            "6/6 [==============================] - 0s 250us/sample - loss: 1.0306e-04\n",
            "Epoch 273/300\n",
            "6/6 [==============================] - 0s 308us/sample - loss: 1.0095e-04\n",
            "Epoch 274/300\n",
            "6/6 [==============================] - 0s 277us/sample - loss: 9.8873e-05\n",
            "Epoch 275/300\n",
            "6/6 [==============================] - 0s 402us/sample - loss: 9.6843e-05\n",
            "Epoch 276/300\n",
            "6/6 [==============================] - 0s 279us/sample - loss: 9.4854e-05\n",
            "Epoch 277/300\n",
            "6/6 [==============================] - 0s 278us/sample - loss: 9.2905e-05\n",
            "Epoch 278/300\n",
            "6/6 [==============================] - 0s 266us/sample - loss: 9.0998e-05\n",
            "Epoch 279/300\n",
            "6/6 [==============================] - 0s 256us/sample - loss: 8.9127e-05\n",
            "Epoch 280/300\n",
            "6/6 [==============================] - 0s 359us/sample - loss: 8.7297e-05\n",
            "Epoch 281/300\n",
            "6/6 [==============================] - 0s 322us/sample - loss: 8.5504e-05\n",
            "Epoch 282/300\n",
            "6/6 [==============================] - 0s 262us/sample - loss: 8.3748e-05\n",
            "Epoch 283/300\n",
            "6/6 [==============================] - 0s 296us/sample - loss: 8.2027e-05\n",
            "Epoch 284/300\n",
            "6/6 [==============================] - 0s 382us/sample - loss: 8.0342e-05\n",
            "Epoch 285/300\n",
            "6/6 [==============================] - 0s 378us/sample - loss: 7.8691e-05\n",
            "Epoch 286/300\n",
            "6/6 [==============================] - 0s 305us/sample - loss: 7.7075e-05\n",
            "Epoch 287/300\n",
            "6/6 [==============================] - 0s 296us/sample - loss: 7.5492e-05\n",
            "Epoch 288/300\n",
            "6/6 [==============================] - 0s 295us/sample - loss: 7.3941e-05\n",
            "Epoch 289/300\n",
            "6/6 [==============================] - 0s 326us/sample - loss: 7.2422e-05\n",
            "Epoch 290/300\n",
            "6/6 [==============================] - 0s 254us/sample - loss: 7.0935e-05\n",
            "Epoch 291/300\n",
            "6/6 [==============================] - 0s 276us/sample - loss: 6.9477e-05\n",
            "Epoch 292/300\n",
            "6/6 [==============================] - 0s 375us/sample - loss: 6.8051e-05\n",
            "Epoch 293/300\n",
            "6/6 [==============================] - 0s 278us/sample - loss: 6.6654e-05\n",
            "Epoch 294/300\n",
            "6/6 [==============================] - 0s 363us/sample - loss: 6.5284e-05\n",
            "Epoch 295/300\n",
            "6/6 [==============================] - 0s 375us/sample - loss: 6.3943e-05\n",
            "Epoch 296/300\n",
            "6/6 [==============================] - 0s 401us/sample - loss: 6.2629e-05\n",
            "Epoch 297/300\n",
            "6/6 [==============================] - 0s 407us/sample - loss: 6.1343e-05\n",
            "Epoch 298/300\n",
            "6/6 [==============================] - 0s 399us/sample - loss: 6.0083e-05\n",
            "Epoch 299/300\n",
            "6/6 [==============================] - 0s 363us/sample - loss: 5.8849e-05\n",
            "Epoch 300/300\n",
            "6/6 [==============================] - 0s 379us/sample - loss: 5.7640e-05\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fe03c03cc18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZ2GAUd2S8Xt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "1144e8a3-0877-42f5-b7db-c4c9f58ab8be"
      },
      "source": [
        "# Save the model\n",
        "save_dir = 'saved_models/1'\n",
        "tf.saved_model.save(model, save_dir)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: saved_models/1/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XeUMrmHZT0hk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "7280c6f0-9baa-4982-ba55-f6e669e6b789"
      },
      "source": [
        "# Convert the model to TFLite\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(save_dir)\n",
        "\n",
        "# Make the conversion and name it tflite\n",
        "tflite_model = converter.convert()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Converted 2 variables to const ops.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T1Uf3DRWUXGT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "76cf9027-098a-4c4a-a2da-759e6ee86bd6"
      },
      "source": [
        "# Save the converted version for use in a mobile device\n",
        "import pathlib\n",
        "tflite_model_file = pathlib.Path('/content/model.tflite')\n",
        "\n",
        "# Write the lite model to the tflite model file\n",
        "tflite_model_file.write_bytes(tflite_model)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "692"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4q0IzwP_U5Vf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make tests for the creared model\n",
        "# If it is perfect, then one can go a head to implement this on mobile device\n",
        "\n",
        "# Initialize the lite interpreter\n",
        "# By loading the model and allocating tensors to it\n",
        "interpreter = tf.lite.Interpreter(model_content=tflite_model)\n",
        "interpreter.allocate_tensors()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "euSejWDdVIVr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the input and output tensors from the loaded model\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c4f6T9mkWjRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Test the model on some random inputs\n",
        "# Generate the inputs based on the training data shape\n",
        "input_shape = input_details[0]['shape']\n",
        "\n",
        "# Initialize where t keep the inputs and outputd from the predictions\n",
        "inputs, outputs = [], []\n",
        "\n",
        "# Generate 100 random sample points\n",
        "for _ in range(100):\n",
        "  \n",
        "  # Get some input data\n",
        "  input_data = np.array(np.random.random_sample(input_shape), dtype=np.float32)\n",
        "  \n",
        "  interpreter.set_tensor(input_details[0]['index'], input_data)\n",
        "  \n",
        "  # Run the interpreter\n",
        "  interpreter.invoke()\n",
        "  \n",
        "  # Get the output resulting from the invokation\n",
        "  tflite_results = interpreter.get_tensor(output_details[0]['index'])\n",
        "  \n",
        "  \n",
        "  # Test the model on the random data\n",
        "  tf_results = model(tf.constant(input_data))\n",
        "  output_data = np.array(tf_results)\n",
        "  \n",
        "  inputs.append(input_data[0][0])\n",
        "  outputs.append(output_data[0][0])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NG6O-Z-4Y84g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "outputId": "5d4441ef-cf29-4720-956e-4d940a351ebc"
      },
      "source": [
        "plt.plot(inputs, outputs)"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fe030a1bfd0>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEVBMPUOCWI0AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ds8DLiAfZWCF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Downlaod the finally tested model for deployment on the mobiel device\n",
        "\n",
        "files.download(tflite_model_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EBr-Hc9kaAtt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}